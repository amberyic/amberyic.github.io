<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
<meta name="baidu-site-verification" content="sQB1vh2KeG" />
<meta name="shenma-site-verification" content="142706695a47156bb1eafc7c9cc28602_1589718210">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://amberyic.github.io').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

<script data-ad-client="ca-pub-4128258433761966" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-166608124-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-166608124-1');
</script>

  <meta name="description" content="使用三台主机搭建hadoop&amp;spark完整教程主要内容: 1)系统安装与配置,2)软件安装与配置,3)hadoop&amp;spark安装与配置,4)集群启动&amp;部署验证,5)集成阿里云,6)通过IDEA提交任务到spark">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop &amp; spark 分布式集群搭建">
<meta property="og:url" content="https://amberyic.github.io/2020/03/21/hadoop-spark-deploy/index.html">
<meta property="og:site_name" content="Zhang Hao&#39;s Blog">
<meta property="og:description" content="使用三台主机搭建hadoop&amp;spark完整教程主要内容: 1)系统安装与配置,2)软件安装与配置,3)hadoop&amp;spark安装与配置,4)集群启动&amp;部署验证,5)集成阿里云,6)通过IDEA提交任务到spark">
<meta property="article:published_time" content="2020-03-20T16:00:00.000Z">
<meta property="article:modified_time" content="2020-05-14T12:05:32.258Z">
<meta property="article:author" content="ZhangHao">
<meta property="article:tag" content="算法工程师 机器学习 深度学习 推荐系统 计算广告">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://amberyic.github.io/2020/03/21/hadoop-spark-deploy/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>hadoop & spark 分布式集群搭建 | Zhang Hao's Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-166608124-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-166608124-1');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Zhang Hao's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">算法工程师的世界</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://amberyic.github.io/2020/03/21/hadoop-spark-deploy/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="ZhangHao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang Hao's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hadoop & spark 分布式集群搭建
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-21 00:00:00" itemprop="dateCreated datePublished" datetime="2020-03-21T00:00:00+08:00">2020-03-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-14 20:05:32" itemprop="dateModified" datetime="2020-05-14T20:05:32+08:00">2020-05-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>使用三台主机搭建hadoop&amp;spark完整教程<br>主要内容: 1)系统安装与配置,2)软件安装与配置,3)hadoop&amp;spark安装与配置,4)集群启动&amp;部署验证,5)集成阿里云,6)通过IDEA提交任务到spark</p>
<a id="more"></a>

<h2 id="系统安装与配置"><a href="#系统安装与配置" class="headerlink" title="系统安装与配置"></a>系统安装与配置</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p><a href="https://ubuntu.com/download/server/thank-you?version=18.04.4&amp;architecture=amd64" target="_blank" rel="noopener">https://ubuntu.com/download/server/thank-you?version=18.04.4&amp;architecture=amd64</a></p>
<h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><ul>
<li>命令行修改</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">使用 hostname 修改当前主机名。</span><br><span class="line">hostname new-hostname</span><br></pre></td></tr></table></figure>
<ul>
<li>修改/etc/sysconfig/network文件,将localhost.localdomain修改为指定hostname并保存文件退出</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vim &#x2F;etc&#x2F;sysconfig&#x2F;network</span><br><span class="line">NETWORKING&#x3D;yes</span><br><span class="line">HOSTNAME&#x3D;localhost.localdomain</span><br></pre></td></tr></table></figure>
<ul>
<li>修改host</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ vi &#x2F;etc&#x2F;hosts</span><br><span class="line">127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1 localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">将127.0.0.1 后指定的hosts改为新的hostname并保存文件退出</span><br></pre></td></tr></table></figure>

<h3 id="安装open-ssh"><a href="#安装open-ssh" class="headerlink" title="安装open-ssh"></a>安装open-ssh</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install openssh-server</span><br><span class="line">$ sudo systemctl status ssh</span><br><span class="line">$ sudo ufw allow ssh</span><br></pre></td></tr></table></figure>

<h3 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo useradd -m hadoop -s &#x2F;bin&#x2F;bash</span><br><span class="line">$ sudo passwd hadoop</span><br><span class="line">修改&#x2F;etc&#x2F;sudoder文件，给hadoop用户增加sudo权限。</span><br></pre></td></tr></table></figure>

<h3 id="修改Host"><a href="#修改Host" class="headerlink" title="修改Host"></a>修改Host</h3><ul>
<li>修改/etc/hosts文件，删除原来127.0.0.1到主机名的映射，增加如下配置。<ul>
<li>前面是集群的IP，可以通过ip -a查看</li>
<li>后面是主机名</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.30.50.42    UbuntuMaster</span><br><span class="line">172.30.50.81    UbuntuSlave1</span><br><span class="line">172.30.50.84    UbuntuSlave2</span><br></pre></td></tr></table></figure>

<h3 id="配置免密码登陆"><a href="#配置免密码登陆" class="headerlink" title="配置免密码登陆"></a>配置免密码登陆</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -t rsa   #产生公钥与私钥对，执行三次回车</span><br><span class="line">$ cat ~&#x2F;.ssh&#x2F;id_rsa.pub &gt;&gt; ~&#x2F;.ssh&#x2F;authorized_keys</span><br><span class="line">将～&#x2F;.ssh目录下的id_rsa.pub,id_rsa,authorized_keys拷贝到其他两台server</span><br></pre></td></tr></table></figure>

<h2 id="软件安装与配置"><a href="#软件安装与配置" class="headerlink" title="软件安装与配置"></a>软件安装与配置</h2><h3 id="Java环境配置"><a href="#Java环境配置" class="headerlink" title="Java环境配置"></a>Java环境配置</h3><ul>
<li>下载Java JDK，放置到/opt目录下，并解压</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mv jdk-8u241-linux-i586.tar.gz &#x2F;opt</span><br><span class="line">cd &#x2F;opt</span><br><span class="line">sudo tar -zxvf .&#x2F;jdk-8u241-linux-i586.tar.gz</span><br></pre></td></tr></table></figure>
<ul>
<li>修改 /etc/profile文件，增加如下语句</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># java</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk1.8.0_241</span><br><span class="line">export CLASSPATH&#x3D;:$JAVA_HOME&#x2F;lib:$JAVA_HOME&#x2F;jre&#x2F;lib:$CLASSPATH</span><br><span class="line">export PATH&#x3D;$JAVA_HOME&#x2F;bin:$JAVA_HOME&#x2F;jre&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure>
<ul>
<li>刷新环境配置, 然后检测Java版本。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line">java -version</span><br><span class="line">如果报文件找不到，执行下面的语句</span><br><span class="line">sudo apt-get install lib32stdc++6</span><br></pre></td></tr></table></figure>

<h3 id="scala环境配置"><a href="#scala环境配置" class="headerlink" title="scala环境配置"></a>scala环境配置</h3><ul>
<li>下载scala，放置到/opt目录下，并解压</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;downloads.lightbend.com&#x2F;scala&#x2F;2.12.10&#x2F;scala-2.12.10.tgz</span><br><span class="line">sudo mv .&#x2F;scala-2.12.10.tgz &#x2F;opt&#x2F;</span><br><span class="line">cd &#x2F;opt&#x2F;</span><br><span class="line">sudo tar -zxf scala-2.12.10.tgz</span><br></pre></td></tr></table></figure>
<ul>
<li>修改环境变量,  vim /etc/profile，添加如下语句</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export SCALA_HOME&#x3D;&#x2F;opt&#x2F;scala-2.12.10</span><br><span class="line">export PATH&#x3D;$PATH:$SCALA_HOME&#x2F;bin</span><br></pre></td></tr></table></figure>
<ul>
<li>刷新环境配置, 然后检测Scala版本。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line">scala -version</span><br></pre></td></tr></table></figure>
<h2 id="hadoop-amp-spark安装与配置"><a href="#hadoop-amp-spark安装与配置" class="headerlink" title="hadoop &amp; spark安装与配置"></a>hadoop &amp; spark安装与配置</h2><h3 id="hadoop的安装与配置"><a href="#hadoop的安装与配置" class="headerlink" title="hadoop的安装与配置"></a>hadoop的安装与配置</h3><ul>
<li>1) 下载hadoop2.7，放置在/opt目录下，并解压</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;hadoop&#x2F;core&#x2F;hadoop-2.7.0&#x2F;hadoop-2.7.0.tar.gz</span><br><span class="line">$ tar -zxvf .&#x2F;hadoop-2.7.0.tar.gz</span><br><span class="line">$ sudo mv hadoop-2.7.0 &#x2F;opt</span><br></pre></td></tr></table></figure>
<ul>
<li>2) 修改环境变量，编辑/etc/profile文件，添加如下程序</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-2.7.0</span><br><span class="line">export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin</span><br><span class="line">export HADOOP_MAPRED_HOME&#x3D;$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME&#x3D;$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME&#x3D;$HADOOP_HOME</span><br><span class="line">export YARN_HOME&#x3D;$HADOOP_HOME</span><br><span class="line">export HADOOP_ROOT_LOGGER&#x3D;INFO,console</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR&#x3D;$HADOOP_HOME&#x2F;lib&#x2F;native</span><br><span class="line">export HADOOP_OPTS&#x3D;&quot;-Djava.library.path&#x3D;$HADOOP_HOME&#x2F;lib&#x2F;native&quot;</span><br></pre></td></tr></table></figure>

<ul>
<li>3) 在hadoop-2.7.0目录下添加目录</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir tmp</span><br><span class="line">$ mkdir hdfs</span><br><span class="line">$ mkdir hdfs&#x2F;name</span><br><span class="line">$ mkdir hdfs&#x2F;data</span><br></pre></td></tr></table></figure>

<ul>
<li>4) 修改$HADOOP_HOME/etc/hadoop/hadoop-env.sh，修改JAVA_HOME 如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk1.8.0_241</span><br></pre></td></tr></table></figure>

<ul>
<li>5) 修改$HADOOP_HOME/etc/hadoop/slaves，将原来的localhost删除，添加如下内容：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">UbuntuSlaver1</span><br><span class="line">UbuntuSlaver2</span><br></pre></td></tr></table></figure>

<ul>
<li>6) 修改$HADOOP_HOME/etc/hadoop/core-site.xml，修改为如下内容：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hdfs:&#x2F;&#x2F;UbuntuMaster:9000&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;io.file.buffer.size&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;131072&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;opt&#x2F;hadoop-2.7.0&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>7) 修改$HADOOP_HOME/etc/hadoop/hdfs-site.xml</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;value&gt;UbuntuMaster:50090&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;value&gt;2&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;value&gt;file:&#x2F;opt&#x2F;hadoop-2.7.0&#x2F;hdfs&#x2F;name&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;value&gt;file:&#x2F;opt&#x2F;hadoop-2.7.0&#x2F;hdfs&#x2F;data&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>8) 在$HADOOP_HOME/etc/hadoop目录下复制template，生成xml，命令如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br><span class="line">修改$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;mapred-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">            &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">            &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;UbuntuMaster:10020&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;UbuntuMaster:19888&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>9) 修改$HADOOP_HOME/etc/hadoop/yarn-site.xml</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.address&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;UbuntuMaster:8032&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;UbuntuMaster:8030&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;UbuntuMaster:8031&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.admin.address&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;UbuntuMaster:8033&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.webapp.address&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;UbuntuMaster:8088&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="spark的安装与配置"><a href="#spark的安装与配置" class="headerlink" title="spark的安装与配置"></a>spark的安装与配置</h3><ul>
<li>1) 下载hadoop2.7，放置在/opt目录下，并解压</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget http:&#x2F;&#x2F;apache.communilink.net&#x2F;spark&#x2F;spark-2.4.5&#x2F;spark-2.4.5-bin-hadoop2.7.tgz</span><br><span class="line">$ tar -zxvf spark-2.4.5-bin-hadoop2.7.tgz</span><br><span class="line">$ sudo mv spark-2.4.5-bin-hadoop2.7 &#x2F;opt</span><br></pre></td></tr></table></figure>
<ul>
<li>2) 修改/etc/profile，增加如下内容。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_HOME&#x3D;&#x2F;opt&#x2F;spark-2.4.5-bin-hadoop2.7</span><br><span class="line">export PATH&#x3D;$PATH:$SPARK_HOME&#x2F;bin</span><br></pre></td></tr></table></figure>
<ul>
<li>3) 配置spark-env.sh文件</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cp $SPARK_HOME&#x2F;conf&#x2F;spark-env.sh.template $SPARK_HOME&#x2F;conf&#x2F;spark-env.sh</span><br><span class="line">在文件末尾添加如下内容：</span><br><span class="line">export SCALA_HOME&#x3D;&#x2F;opt&#x2F;scala-2.12.10</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk1.8.0_241</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-2.7.0</span><br><span class="line">export SPARK_WORKER_MEMORY&#x3D;6g</span><br><span class="line">export HADOOP_CONF_DIR&#x3D;&#x2F;opt&#x2F;hadoop-2.7.0&#x2F;etc&#x2F;hadoop</span><br><span class="line">export SPARK_MASTER_IP&#x3D;172.30.50.42</span><br><span class="line">export LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:$HADOOP_HOME&#x2F;lib&#x2F;native</span><br></pre></td></tr></table></figure>

<ul>
<li>4) 配置slaves文件,添加如下内容</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cp $SPARK_HOME&#x2F;conf&#x2F;slaves.template $SPARK_HOME&#x2F;conf&#x2F;slaves</span><br><span class="line">在文件末尾添加如下内容：</span><br><span class="line">UbuntuMaster</span><br><span class="line">UbuntuSlave1</span><br><span class="line">UbuntuSlave2</span><br></pre></td></tr></table></figure>

<h3 id="同步配置-amp-初始化集群"><a href="#同步配置-amp-初始化集群" class="headerlink" title="同步配置&amp;初始化集群"></a>同步配置&amp;初始化集群</h3><ul>
<li>1) 拷贝软件配置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ scp -r &#x2F;opt&#x2F;jdk1.8.0_241 hadoop@UbuntuSlave1:&#x2F;opt</span><br><span class="line">$ scp -r &#x2F;opt&#x2F;jdk1.8.0_241 hadoop@UbuntuSlave2:&#x2F;opt</span><br><span class="line">$ scp -r &#x2F;opt&#x2F;hadoop-2.7.0 hadoop@UbuntuSlave1:&#x2F;opt</span><br><span class="line">$ scp -r &#x2F;opt&#x2F;hadoop-2.7.0 hadoop@UbuntuSlave2:&#x2F;opt</span><br><span class="line">$ scp -r &#x2F;opt&#x2F;spark-2.4.5-bin-hadoop2.7 hadoop@UbuntuSlave1:&#x2F;opt</span><br><span class="line">$ scp -r &#x2F;opt&#x2F;spark-2.4.5-bin-hadoop2.7 hadoop@UbuntuSlave2:&#x2F;opt</span><br></pre></td></tr></table></figure>

<ul>
<li>2) 复制/etc/profile的配置到Slave</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># java</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk1.8.0_241</span><br><span class="line">export CLASSPATH&#x3D;:$JAVA_HOME&#x2F;lib:$JAVA_HOME&#x2F;jre&#x2F;lib:$CLASSPATH</span><br><span class="line">export PATH&#x3D;$JAVA_HOME&#x2F;bin:$JAVA_HOME&#x2F;jre&#x2F;bin:$PATH</span><br><span class="line"></span><br><span class="line"># scala</span><br><span class="line">export SCALA_HOME&#x3D;&#x2F;opt&#x2F;scala-2.12.10</span><br><span class="line">export PATH&#x3D;$PATH:$SCALA_HOME&#x2F;bin</span><br><span class="line"></span><br><span class="line"># hadoop</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-2.7.0</span><br><span class="line">export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin</span><br><span class="line">export HADOOP_MAPRED_HOME&#x3D;$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME&#x3D;$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME&#x3D;$HADOOP_HOME</span><br><span class="line">export YARN_HOME&#x3D;$HADOOP_HOME</span><br><span class="line">export HADOOP_ROOT_LOGGER&#x3D;INFO,console</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR&#x3D;$HADOOP_HOME&#x2F;lib&#x2F;native</span><br><span class="line">export HADOOP_OPTS&#x3D;&quot;-Djava.library.path&#x3D;$HADOOP_HOME&#x2F;lib&#x2F;native&quot;</span><br><span class="line"></span><br><span class="line"># spark</span><br><span class="line">export SPARK_HOME&#x3D;&#x2F;opt&#x2F;spark-2.4.5-bin-hadoop2.7</span><br><span class="line">export PATH&#x3D;$PATH:$SPARK_HOME&#x2F;bin</span><br></pre></td></tr></table></figure>

<ul>
<li>3) 初始化Hadoop集群</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop namenode -format</span><br></pre></td></tr></table></figure>

<h2 id="集群启动-amp-部署验证"><a href="#集群启动-amp-部署验证" class="headerlink" title="集群启动&amp;部署验证"></a>集群启动&amp;部署验证</h2><h3 id="hadoop集群启动"><a href="#hadoop集群启动" class="headerlink" title="hadoop集群启动"></a>hadoop集群启动</h3><ul>
<li>1) 在Master节点，执行一下命令，启动集群。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;opt&#x2F;hadoop-2.7.0&#x2F;sbin&#x2F;start-all.sh</span><br></pre></td></tr></table></figure></li>
<li>2）查看Hadoop是否启动成功，输入命令：jps<br>Master显示：SecondaryNameNode，ResourceManager，NameNode<br>Slaver显示：NodeManager，DataNode</li>
<li>3) 管理界面<br>访问<a href="http://UbuntuMaster:50070" target="_blank" rel="noopener">http://UbuntuMaster:50070</a>, 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。</li>
</ul>
<h3 id="hadoop集群验证"><a href="#hadoop集群验证" class="headerlink" title="hadoop集群验证"></a>hadoop集群验证</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd  $HADOOP_HOME</span><br><span class="line"></span><br><span class="line">bin&#x2F;hadoop fs -rm -r &#x2F;output</span><br><span class="line">bin&#x2F;hadoop fs -mkdir &#x2F;input</span><br><span class="line">bin&#x2F;hadoop fs -put $HADOOP_HOME&#x2F;README.txt &#x2F;input</span><br><span class="line">bin&#x2F;hadoop fs -ls  &#x2F;input</span><br><span class="line">bin&#x2F;hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-2.7.0.jar wordcount  &#x2F;input&#x2F;README.txt  &#x2F;output</span><br><span class="line"></span><br><span class="line">bin&#x2F;hadoop fs -ls  &#x2F;output</span><br><span class="line">bin&#x2F;hadoop fs -cat &#x2F;output&#x2F;part-r-00000</span><br></pre></td></tr></table></figure>

<h3 id="spark集群启动"><a href="#spark集群启动" class="headerlink" title="spark集群启动"></a>spark集群启动</h3><ul>
<li>1) 在Master节点，执行一下命令，启动集群。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;opt&#x2F;spark-2.4.5-bin-hadoop2.7&#x2F;sbin&#x2F;start-all.sh</span><br></pre></td></tr></table></figure></li>
<li>2）查看Hadoop是否启动成功，输入命令：jps<br>Master显示：Master<br>Slaver显示：Worker</li>
<li>3）管理界面<br>访问<a href="http://UbuntuMaster:8080" target="_blank" rel="noopener">http://UbuntuMaster:8080</a>, 可以看到三个Worker</li>
</ul>
<h3 id="spark集群验证"><a href="#spark集群验证" class="headerlink" title="spark集群验证"></a>spark集群验证</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark:&#x2F;&#x2F;UbuntuMaster:7077 \</span><br><span class="line">--executor-memory 1G --total-executor-cores 2 \</span><br><span class="line">&#x2F;opt&#x2F;spark-2.4.5-bin-hadoop2.7&#x2F;examples&#x2F;jars&#x2F;spark-examples_2.11-2.4.5.jar \</span><br><span class="line">100</span><br></pre></td></tr></table></figure>

<h2 id="集成阿里云"><a href="#集成阿里云" class="headerlink" title="集成阿里云"></a>集成阿里云</h2><p>hadoop 2.9以后才支持oss的读写，我们使用的是2.7，需要自己配置。</p>
<ul>
<li><p>1）下载支持包，并解压hadoop-aliyun-2.7.2.jar<br><a href="http://gosspublic.alicdn.com/hadoop-spark/hadoop-oss-2.7.2.tar.gz" target="_blank" rel="noopener">http://gosspublic.alicdn.com/hadoop-spark/hadoop-oss-2.7.2.tar.gz</a></p>
</li>
<li><p>2）将文件hadoop-aliyun-2.7.2.jar复制到<code>$HADOOP_HOME/share/hadoop/tools/lib/</code>目录下</p>
</li>
<li><p>3）修改<code>$HADOOP_HOME/libexec/hadoop-config.sh</code>文件，再文件末尾增加<code>CLASSPATH=$CLASSPATH:$TOOL_PATH</code></p>
</li>
<li><p>4）修改core-site.xml的配置</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.oss.accessKeyId&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;xxxx&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.oss.accessKeySecret&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;xxx&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.oss.endpoint&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;oss-us-east-1.aliyuncs.com&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.oss.impl&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.oss.buffer.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;tmp&#x2F;oss&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.oss.connection.secure.enabled&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.oss.connection.maximum&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;2048&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure>

<h2 id="通过IDEA提交任务到spark"><a href="#通过IDEA提交任务到spark" class="headerlink" title="通过IDEA提交任务到spark"></a>通过IDEA提交任务到spark</h2><p><a href="https://blog.csdn.net/yiluohan0307/article/details/80048765" target="_blank" rel="noopener">https://blog.csdn.net/yiluohan0307/article/details/80048765</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/21/hexo-github-deploy/" rel="prev" title="Hexo + Github Page搭建博客">
      <i class="fa fa-chevron-left"></i> Hexo + Github Page搭建博客
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/10/5-classic-algorithms-1-exhaustive-method/" rel="next" title="五大经典算法-1.穷举法">
      五大经典算法-1.穷举法 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#系统安装与配置"><span class="nav-number">1.</span> <span class="nav-text">系统安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#下载"><span class="nav-number">1.1.</span> <span class="nav-text">下载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#修改主机名"><span class="nav-number">1.2.</span> <span class="nav-text">修改主机名</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装open-ssh"><span class="nav-number">1.3.</span> <span class="nav-text">安装open-ssh</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建用户"><span class="nav-number">1.4.</span> <span class="nav-text">创建用户</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#修改Host"><span class="nav-number">1.5.</span> <span class="nav-text">修改Host</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置免密码登陆"><span class="nav-number">1.6.</span> <span class="nav-text">配置免密码登陆</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#软件安装与配置"><span class="nav-number">2.</span> <span class="nav-text">软件安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Java环境配置"><span class="nav-number">2.1.</span> <span class="nav-text">Java环境配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#scala环境配置"><span class="nav-number">2.2.</span> <span class="nav-text">scala环境配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hadoop-amp-spark安装与配置"><span class="nav-number">3.</span> <span class="nav-text">hadoop &amp; spark安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop的安装与配置"><span class="nav-number">3.1.</span> <span class="nav-text">hadoop的安装与配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark的安装与配置"><span class="nav-number">3.2.</span> <span class="nav-text">spark的安装与配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#同步配置-amp-初始化集群"><span class="nav-number">3.3.</span> <span class="nav-text">同步配置&amp;初始化集群</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#集群启动-amp-部署验证"><span class="nav-number">4.</span> <span class="nav-text">集群启动&amp;部署验证</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop集群启动"><span class="nav-number">4.1.</span> <span class="nav-text">hadoop集群启动</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop集群验证"><span class="nav-number">4.2.</span> <span class="nav-text">hadoop集群验证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark集群启动"><span class="nav-number">4.3.</span> <span class="nav-text">spark集群启动</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark集群验证"><span class="nav-number">4.4.</span> <span class="nav-text">spark集群验证</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#集成阿里云"><span class="nav-number">5.</span> <span class="nav-text">集成阿里云</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#通过IDEA提交任务到spark"><span class="nav-number">6.</span> <span class="nav-text">通过IDEA提交任务到spark</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="ZhangHao"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">ZhangHao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/amberyic" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;amberyic" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhanghaokdd@163.com" title="E-Mail → mailto:zhanghaokdd@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/chanming1989" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;chanming1989" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/amberyic" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;amberyic" rel="noopener" target="_blank"><i class="fa fa-fw fa-gratipay"></i>知乎</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/amberyic" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;amberyic" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/amberyic" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;amberyic" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZhangHao</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.0
  </div>


<div class="powered-by">
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <i class="fa fa-user-md"></i>
    <span id="busuanzi_container_site_uv">
        本站访客数:<span id="busuanzi_value_site_uv"></span>
    </span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_pv">
        本站访问量<span id="busuanzi_value_site_pv"></span>
    </span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
